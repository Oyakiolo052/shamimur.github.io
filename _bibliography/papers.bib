---
---
@inproceedings{wang-etal-2024-m4,
    abbr={M4},
    selected={true},
    title = "M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection",
    author = "Wang, Yuxia  and
      Mansurov, Jonibek  and
      Ivanov, Petar  and
      Su, Jinyan  and
      Shelmanov, Artem  and
      Tsvigun, Akim  and
      Whitehouse, Chenxi  and
      Mohammed Afzal, Osama  and
      Mahmoud, Tarek  and
      Sasaki, Toru  and
      Arnold, Thomas  and
      Aji, Alham Fikri  and
      Habash, Nizar  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-long.83/",
    pages = "1369--1407",
}

@inproceedings{wang-etal-2024-m4gt,
    abbr={M4GT},
    selected={true},
    title = "{M}4{GT}-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection",
    author = "Wang, Yuxia  and
      Mansurov, Jonibek  and
      Ivanov, Petar  and
      Su, Jinyan  and
      Shelmanov, Artem  and
      Tsvigun, Akim  and
      Mohammed Afzal, Osama  and
      Mahmoud, Tarek  and
      Puccetti, Giovanni  and
      Arnold, Thomas  and
      Aji, Alham  and
      Habash, Nizar  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.218/",
    doi = "10.18653/v1/2024.acl-long.218",
    pages = "3964--3992",
}

@inproceedings{bevendorff2025overview,
  abbr={CLEF2025},
  selected={false},
  title={Overview of PAN 2025: Generative AI Detection, Multilingual Text Detoxification, Multi-Author Writing Style Analysis, and Generative Plagiarism Detection},
  author={Bevendorff, Janek and Dementieva, Daryna and Fr{\"o}be, Maik and Gipp, Bela and Greiner-Petter, Andr{\'e} and Mayerl, Jussi Karlgren5 Maximilian and Nakov, Preslav and Panchenko, Alexander and Potthast, Martin and Shelmanov, Artem and others},
  booktitle={ECIR},
  year={2025}
}

@article{ali2024detection,
  abbr={UrduNewsDetection},
  selected={false},
  title={Detection of Human and Machine-Authored Fake News in Urdu},
  author={Ali, Muhammad Zain and Wang, Yuxia and Pfahringer, Bernhard and Smith, Tony},
  journal={ACL 2025},
  year={2024}
}

@inproceedings{wang-etal-2024-rethinking,
    abbr={RethinkSTS},
    selected={false},
    title = "Rethinking {STS} and {NLI} in Large Language Models",
    author = "Wang, Yuxia  and
      Wang, Minghan  and
      Nakov, Preslav",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.65/",
    pages = "965--982",
}

@inproceedings{iqbal-etal-2024-openfactcheck,
    abbr={OpenFactCheck},
    selected={true},
    title = "{O}pen{F}act{C}heck: A Unified Framework for Factuality Evaluation of {LLM}s",
    author = "Iqbal*, Hasan  and
      Wang*, Yuxia  and
      Wang, Minghan  and
      Georgiev, Georgi Nenkov  and
      Geng, Jiahui  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Hernandez Farias, Delia Irazu  and
      Hope, Tom  and
      Li, Manling",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-demo.23/",
    doi = "10.18653/v1/2024.emnlp-demo.23",
    pages = "219--229",
}

@inproceedings{wang-etal-2024-factcheck,
    abbr={Factcheck-Bench},
    selected={true},
    title = "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-checkers",
    author = "Wang, Yuxia  and
      Gangi Reddy, Revanth  and
      Mujahid, Zain Muhammad  and
      Arora, Arnav  and
      Rubashevskii, Aleksandr  and
      Geng, Jiahui  and
      Mohammed Afzal, Osama  and
      Pan, Liangming  and
      Borenstein, Nadav  and
      Pillai, Aditya  and
      Augenstein, Isabelle  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.830/",
    doi = "10.18653/v1/2024.findings-emnlp.830",
    pages = "14199--14230",
}

@article{wang-etal-2023-collective,
    abbr={Collective STS},
    selected={false},
    title = "Collective Human Opinions in Semantic Textual Similarity",
    author = "Wang, Yuxia  and
      Tao, Shimin  and
      Xie, Ning  and
      Yang, Hao  and
      Baldwin, Timothy  and
      Verspoor, Karin",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "11",
    year = "2023",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2023.tacl-1.56/",
    doi = "10.1162/tacl_a_00584",
    pages = "997--1013",
}


@inproceedings{wang-etal-2024-exploring,
    abbr={ASR},
    selected={false},
    title = "Exploring the Potential of Multimodal {LLM} with Knowledge-Intensive Multimodal {ASR}",
    author = "Wang, Minghan  and
      Wang, Yuxia  and
      Vu, Thuy-Trang  and
      Shareghi, Ehsan  and
      Haf, Reza",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.776/",
    doi = "10.18653/v1/2024.findings-emnlp.776",
    pages = "13274--13288",
    abstract = "Recent advancements in multimodal large language models (MLLMs) have made significant progress in integrating information across various modalities, yet real-world applications in educational and scientific domains remain challenging. This paper introduces the Multimodal Scientific ASR (MS-ASR) task, which focuses on transcribing scientific conference videos by leveraging visual information from slides to enhance the accuracy of technical terminologies. Realized that traditional metrics like WER fall short in assessing performance accurately, prompting the proposal of severity-aware WER (SWER) that considers the content type and severity of ASR errors. We propose the Scientific Vision Augmented ASR (SciVASR) framework as a baseline method, enabling MLLMs to improve transcript quality through post-editing. Evaluations of state-of-the-art MLLMs, including GPT-4o, show a 45{\%} improvement over speech-only baselines, highlighting the importance of multimodal information integration."
}

@inproceedings{wang-etal-2024-demystifying,
    abbr={SFT},
    selected={false},
    title = "Demystifying Instruction Mixing for Fine-tuning Large Language Models",
    author = "Wang, Renxi  and
      Li, Haonan  and
      Wu, Minghao  and
      Wang, Yuxia  and
      Han, Xudong  and
      Zhang, Chiyu  and
      Baldwin, Timothy",
    editor = "Fu, Xiyan  and
      Fleisig, Eve",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-srw.15/",
    doi = "10.18653/v1/2024.acl-srw.15",
    pages = "68--75",
    ISBN = "979-8-89176-097-4",
    abstract = "Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study categorizes instructions into three primary types: NLP downstream tasks, coding, and general chat. We explore the effects of instruction tuning on different combinations of datasets on LLM performance, and find that certain instruction types are more advantageous for specific applications but can negatively impact other areas. This work provides insights into instruction mixtures, laying the foundations for future research."
}


@inproceedings{li-etal-2025-loki,
    abbr={Loki},
    selected={false},
    title = "Loki: An Open-Source Tool for Fact Verification",
    author = "Li, Haonan  and
      Han, Xudong  and
      Wang, Hao  and
      Wang, Yuxia  and
      Wang, Minghan  and
      Xing, Rui  and
      Geng, Yilin  and
      Zhai, Zenan  and
      Nakov, Preslav  and
      Baldwin, Timothy",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven  and
      Mather, Brodie  and
      Dras, Mark",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics: System Demonstrations",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-demos.4/",
    pages = "28--36",
    abstract = "We introduce Loki, an open-source tool designed to address the growing problem of misinformation. Loki adopts a human-centered approach, striking a balance between the quality of fact-checking and the cost of human involvement. It decomposes the fact-checking task into a five-step pipeline: breaking down long texts into individual claims, assessing their check-worthiness, generating queries, retrieving evidence, and verifying the claims. Instead of fully automating the claim verification process, provides essential information at each step to assist human judgment, especially for general users such as journalists and content moderators. Moreover, it has been optimized for latency, robustness, and cost efficiency at a commercially usable level. Loki is released under an MIT license and is available on GitHub. We also provide a video presenting the system and its capabilities."
}

@inproceedings{li-etal-2025-libra,
    abbr={Libra-leaderboard},
    selected={false},
    title = "Libra-Leaderboard: Towards Responsible {AI} through a Balanced Leaderboard of Safety and Capability",
    author = "Li, Haonan  and
      Han, Xudong  and
      Zhai, Zenan  and
      Mu, Honglin  and
      Wang, Hao  and
      Zhang, Zhenxuan  and
      Geng, Yilin  and
      Lin, Shom  and
      Wang, Renxi  and
      Shelmanov, Artem  and
      Qi, Xiangyu  and
      Wang, Yuxia  and
      Hong, Donghai  and
      Yuan, Youliang  and
      Chen, Meng  and
      Tu, Haoqin  and
      Koto, Fajri  and
      Zeng, Cong  and
      Kuribayashi, Tatsuki  and
      Bhardwaj, Rishabh  and
      Zhao, Bingchen  and
      Duan, Yawen  and
      Liu, Yi  and
      Alghamdi, Emad A.  and
      Yang, Yaodong  and
      Dong, Yinpeng  and
      Poria, Soujanya  and
      Liu, Pengfei  and
      Liu, Zhengzhong  and
      Ren, Hector Xuguang  and
      Hovy, Eduard  and
      Gurevych, Iryna  and
      Nakov, Preslav  and
      Choudhury, Monojit  and
      Baldwin, Timothy",
    editor = "Dziri, Nouha  and
      Ren, Sean (Xiang)  and
      Diao, Shizhe",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (System Demonstrations)",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-demo.23/",
    doi = "10.18653/v1/2025.naacl-demo.23",
    pages = "268--286",
    ISBN = "979-8-89176-191-9",
    abstract = "As large language models (LLMs) continue to evolve, leaderboards play a significant role in steering their development. Existing leaderboards often prioritize model capabilities while overlooking safety concerns, leaving a significant gap in responsible AI development. To address this gap, we introduce Libra-Leaderboard, a comprehensive framework designed to rank LLMs through a balanced evaluation of performance and safety. Combining a dynamic leaderboard with an interactive LLM arena, Libra-Leaderboard encourages the joint optimization of capability and safety. Unlike traditional approaches that average performance and safety metrics, Libra-Leaderboard uses a distance-to-optimal-score method to calculate the overall rankings. This approach incentivizes models to achieve a balance rather than excelling in one dimension at the expense of some other ones. In the first release, Libra-Leaderboard evaluates 26 mainstream LLMs from 14 leading organizations, identifying critical safety challenges even in state-of-the-art models."
}

@inproceedings{wang-etal-2022-noisy,
    abbr={NoisyRegulation},
    selected={false},
    title = "Noisy Label Regularisation for Textual Regression",
    author = "Wang, Yuxia  and
      Baldwin, Timothy  and
      Verspoor, Karin",
    editor = "Calzolari, Nicoletta  and
      Huang, Chu-Ren  and
      Kim, Hansaem  and
      Pustejovsky, James  and
      Wanner, Leo  and
      Choi, Key-Sun  and
      Ryu, Pum-Mo  and
      Chen, Hsin-Hsi  and
      Donatelli, Lucia  and
      Ji, Heng  and
      Kurohashi, Sadao  and
      Paggio, Patrizia  and
      Xue, Nianwen  and
      Kim, Seokhwan  and
      Hahm, Younggyun  and
      He, Zhong  and
      Lee, Tony Kyungil  and
      Santus, Enrico  and
      Bond, Francis  and
      Na, Seung-Hoon",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.371/",
    pages = "4228--4240",
    abstract = "Training with noisy labelled data is known to be detrimental to model performance, especially for high-capacity neural network models in low-resource domains. Our experiments suggest that standard regularisation strategies, such as weight decay and dropout, are ineffective in the face of noisy labels. We propose a simple noisy label detection method that prevents error propagation from the input layer. The approach is based on the observation that the projection of noisy labels is learned through memorisation at advanced stages of learning, and that the Pearson correlation is sensitive to outliers. Extensive experiments over real-world human-disagreement annotations as well as randomly-corrupted and data-augmented labels, across various tasks and domains, demonstrate that our method is effective, regularising noisy labels and improving generalisation performance."
}


@inproceedings{wang-etal-2024-factuality,
    abbr={Factuality survey},
    selected={false},
    title = "Factuality of Large Language Models: A Survey",
    author = "Wang, Yuxia  and
      Wang, Minghan  and
      Manzoor, Muhammad Arslan  and
      Liu, Fei  and
      Georgiev, Georgi Nenkov  and
      Das, Rocktim Jyoti  and
      Nakov, Preslav",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.1088/",
    doi = "10.18653/v1/2024.emnlp-main.1088",
    pages = "19519--19529",
    abstract = "Large language models (LLMs), especially when instruction-tuned for chat, have become part of our daily lives, freeing people from the process of searching, extracting, and integrating information from multiple sources by offering a straightforward answer to a variety of questions in a single place. Unfortunately, in many cases, LLM responses are factually incorrect, which limits their applicability in real-world scenarios. As a result, research on evaluating and improving the factuality of LLMs has attracted a lot of research attention recently. In this survey, we critically analyze existing work with the aim to identify the major challenges and their associated causes, pointing out to potential solutions for improving the factuality of LLMs, and analyzing the obstacles to automated factuality evaluation for open-ended text generation. We further offer an outlook on where future research should go."
}

@article{wang2024conversational,
  abbr={SimulMT},
  selected={false},
  title={Conversational simulmt: Efficient simultaneous translation with large language models},
  author={Wang, Minghan and Vu, Thuy-Trang and Wang, Yuxia and Shareghi, Ehsan and Haffari, Gholamreza},
  journal={arXiv preprint arXiv:2402.10552},
  year={2024}
}


@inproceedings{geng-etal-2024-survey,
    abbr={Uncertainty srvey},
    selected={false},
    title = "A Survey of Confidence Estimation and Calibration in Large Language Models",
    author = "Geng, Jiahui  and
      Cai, Fengyu  and
      Wang, Yuxia  and
      Koeppl, Heinz  and
      Nakov, Preslav  and
      Gurevych, Iryna",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.366/",
    doi = "10.18653/v1/2024.naacl-long.366",
    pages = "6577--6595",
    abstract = "Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks in various domains. Despite their impressive performance, they can be unreliable due to factual errors in their generations. Assessing their confidence and calibrating them across different tasks can help mitigate risks and enable LLMs to produce better generations. There has been a lot of recent research aiming to address this, but there has been no comprehensive overview to organize it and to outline the main lessons learned. The present survey aims to bridge this gap. In particular, we outline the challenges and we summarize recent technical advancements for LLM confidence estimation and calibration. We further discuss their applications and suggest promising directions for future work."
}

@inproceedings{wang-etal-2024-chinese,
    abbr={CDNA},
    selected={true},
    title = "A {C}hinese Dataset for Evaluating the Safeguards in Large Language Models",
    author = "Wang, Yuxia  and
      Zhai, Zenan  and
      Li, Haonan  and
      Han, Xudong  and
      Lin, Shom  and
      Zhang, Zhenxuan  and
      Zhao, Angela  and
      Nakov, Preslav  and
      Baldwin, Timothy",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.184/",
    doi = "10.18653/v1/2024.findings-acl.184",
    pages = "3106--3119",
    abstract = "Many studies have demonstrated that large language models (LLMs) can produce harmful responses, exposing users to unexpected risks. Previous studies have proposed comprehensive taxonomies of LLM risks, as well as corresponding prompts that can be used to examine LLM safety. However, the focus has been almost exclusively on English. We aim to broaden LLM safety research by introducing a dataset for the safety evaluation of Chinese LLMs, and extending it to better identify false negative and false positive examples in terms of risky prompt rejections. We further present a set of fine-grained safety assessment criteria for each risk type, facilitating both manual annotation and automatic evaluation in terms of LLM response harmfulness. Our experiments over five LLMs show that region-specific risks are the prevalent risk type. Warning: this paper contains example data that may be offensive, harmful, or biased. Our data is available at https://github.com/Libr-AI/do-not-answer."
}


@inproceedings{wang-etal-2024-answer,
    abbr={DNA},
    selected={true},
    title = "Do-Not-Answer: Evaluating Safeguards in {LLM}s",
    author = "Wang, Yuxia  and
      Li, Haonan  and
      Han, Xudong  and
      Nakov, Preslav  and
      Baldwin, Timothy",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.61/",
    pages = "896--911",
    abstract = "With the rapid evolution of large language models (LLMs), new and hard-to-predict harmful capabilities are emerging. This requires developers to identify potential risks through the evaluation of ``dangerous capabilities'' in order to responsibly deploy LLMs. Here we aim to facilitate this process. In particular, we collect an open-source dataset to evaluate the safeguards in LLMs, to facilitate the deployment of safer open-source LLMs at a low cost. Our dataset is curated and filtered to consist only of instructions that responsible language models should not follow. We assess the responses of six popular LLMs to these instructions, and we find that simple BERT-style classifiers can achieve results that are comparable to GPT-4 on automatic safety evaluation. Our data and code are available at https://github.com/Libr-AI/do-not-answer"
}

@inproceedings{xie-etal-2025-fire,
    abbr={FIRE},
    selected={false},
    title = "{FIRE}: Fact-checking with Iterative Retrieval and Verification",
    author = "Xie, Zhuohan  and
      Xing, Rui  and
      Wang, Yuxia  and
      Geng, Jiahui  and
      Iqbal, Hasan  and
      Sahnan, Dhruv  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2025",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-naacl.158/",
    doi = "10.18653/v1/2025.findings-naacl.158",
    pages = "2901--2914",
    ISBN = "979-8-89176-195-7",
    abstract = "Fact-checking long-form text is challenging, and it is therefore common practice to break it down into multiple atomic claims. The typical approach to fact-checking these atomic claims involves retrieving a fixed number of pieces of evidence, followed by a verification step. However, this method is usually not cost-effective, as it underutilizes the verification model{'}s internal knowledge of the claim and fails to replicate the iterative reasoning process in human search strategies. To address these limitations, we propose FIRE, a novel agent-based framework that integrates evidence retrieval and claim verification in an iterative manner. Specifically, FIRE employs a unified mechanism to decide whether to provide a final answer or generate a subsequent search query, based on its confidence in the current judgment. We compare FIRE with other strong fact-checking frameworks and find that it achieves slightly better performance while reducing large language model (LLM) costs by an average of 7.6 times and search costs by 16.5 times. These results indicate that FIRE holds promise for application in large-scale fact-checking operations."
}


@inproceedings{ashraf-etal-2025-arabic,
    abbr={ADNA},
    selected={false},
    title = "{A}rabic Dataset for {LLM} Safeguard Evaluation",
    author = "Ashraf, Yasser  and
      Wang, Yuxia  and
      Gu, Bin  and
      Nakov, Preslav  and
      Baldwin, Timothy",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-long.285/",
    doi = "10.18653/v1/2025.naacl-long.285",
    pages = "5529--5546",
    ISBN = "979-8-89176-189-6",
    abstract = "The growing use of large language models (LLMs) has raised concerns regarding their safety. While many studies have focused on English, the safety of LLMs in Arabic, with its linguistic and cultural complexities, remains under-explored. Here, we aim to bridge this gap. In particular, we present an Arab-region-specific safety evaluation dataset consisting of 5,799 questions, including direct attacks, indirect attacks, and harmless requests with sensitive words, adapted to reflect the socio-cultural context of the Arab world. To uncover the impact of different stances in handling sensitive and controversial topics, we propose a dual-perspective evaluation framework. It assesses the LLM responses from both governmental and opposition viewpoints. Experiments over five leading Arabic-centric and multilingual LLMs reveal substantial disparities in their safety performance. This reinforces the need for culturally specific datasets to ensure the responsible deployment of LLMs."
}

@article{lin2025against,
  abbr={Jailbreak survey},
  selected={false},
  title={Against The Achilles' Heel: A Survey on Red Teaming for Generative Models},
  author={Lin, Lizhi and Mu, Honglin and Zhai, Zenan and Wang, Minghan and Wang, Yuxia and Wang, Renxi and Gao, Junjie and Zhang, Yixuan and Che, Wanxiang and Baldwin, Timothy and others},
  journal={Journal of Artificial Intelligence Research},
  volume={82},
  pages={687--775},
  year={2025}
}

@inproceedings{wang-etal-2022-capture,
    abbr={NLI},
    selected={false},
    title = "Capture Human Disagreement Distributions by Calibrated Networks for Natural Language Inference",
    author = "Wang, Yuxia  and
      Wang, Minghan  and
      Chen, Yimeng  and
      Tao, Shimin  and
      Guo, Jiaxin  and
      Su, Chang  and
      Zhang, Min  and
      Yang, Hao",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.120/",
    doi = "10.18653/v1/2022.findings-acl.120",
    pages = "1524--1535",
    abstract = "Natural Language Inference (NLI) datasets contain examples with highly ambiguous labels due to its subjectivity. Several recent efforts have been made to acknowledge and embrace the existence of ambiguity, and explore how to capture the human disagreement distribution. In contrast with directly learning from gold ambiguity labels, relying on special resource, we argue that the model has naturally captured the human ambiguity distribution as long as it{'}s calibrated, i.e. the predictive probability can reflect the true correctness likelihood. Our experiments show that when model is well-calibrated, either by label smoothing or temperature scaling, it can obtain competitive performance as prior work, on both divergence scores between predictive probability and the true human opinion distribution, and the accuracy. This reveals the overhead of collecting gold ambiguity labels can be cut, by broadly solving how to calibrate the NLI network."
}

@inproceedings{wang-etal-2020-evaluating,
    abbr={STS},
    selected={false},
    title = "Evaluating the Utility of Model Configurations and Data Augmentation on Clinical Semantic Textual Similarity",
    author = "Wang, Yuxia  and
      Liu, Fei  and
      Verspoor, Karin  and
      Baldwin, Timothy",
    editor = "Demner-Fushman, Dina  and
      Cohen, Kevin Bretonnel  and
      Ananiadou, Sophia  and
      Tsujii, Junichi",
    booktitle = "Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.bionlp-1.11/",
    doi = "10.18653/v1/2020.bionlp-1.11",
    pages = "105--111",
    abstract = "In this paper, we apply pre-trained language models to the Semantic Textual Similarity (STS) task, with a specific focus on the clinical domain. In low-resource setting of clinical STS, these large models tend to be impractical and prone to overfitting. Building on BERT, we study the impact of a number of model design choices, namely different fine-tuning and pooling strategies. We observe that the impact of domain-specific fine-tuning on clinical STS is much less than that in the general domain, likely due to the concept richness of the domain. Based on this, we propose two data augmentation techniques. Experimental results on N2C2-STS 1 demonstrate substantial improvements, validating the utility of the proposed methods."
}

@inproceedings{wang-etal-2022-diformer,
    abbr={Diformer},
    selected={false},
    title = "Diformer: Directional Transformer for Neural Machine Translation",
    author = "Wang, Minghan  and
      Guo, Jiaxin  and
      Wang, Yuxia  and
      Wei, Daimeng  and
      Shang, Hengchao  and
      Li, Yinglu  and
      Su, Chang  and
      Chen, Yimeng  and
      Zhang, Min  and
      Tao, Shimin  and
      Yang, Hao",
    editor = {Moniz, Helena  and
      Macken, Lieve  and
      Rufener, Andrew  and
      Barrault, Lo{\"i}c  and
      Costa-juss{\`a}, Marta R.  and
      Declercq, Christophe  and
      Koponen, Maarit  and
      Kemp, Ellie  and
      Pilos, Spyridon  and
      Forcada, Mikel L.  and
      Scarton, Carolina  and
      Van den Bogaert, Joachim  and
      Daems, Joke  and
      Tezcan, Arda  and
      Vanroy, Bram  and
      Fonteyne, Margot},
    booktitle = "Proceedings of the 23rd Annual Conference of the European Association for Machine Translation",
    month = jun,
    year = "2022",
    address = "Ghent, Belgium",
    publisher = "European Association for Machine Translation",
    url = "https://aclanthology.org/2022.eamt-1.11/",
    pages = "81--90",
    abstract = "Autoregressive (AR) and Non-autoregressive (NAR) models have their own superiority on the performance and latency, combining them into one model may take advantage of both. Current combination frameworks focus more on the integration of multiple decoding paradigms with a unified generative model, e.g. Masked Language Model. However, the generalization can be harmful on the performance due to the gap between training objective and inference. In this paper, we aim to close the gap by preserving the original objective of AR and NAR under a unified framework. Specifically, we propose the Directional Transformer (Diformer) by jointly modelling AR and NAR into three generation directions (left-to-right, right-to-left and straight) with a newly introduced direction variable, which works by controlling the prediction of each token to have specific dependencies under that direction. The unification achieved by direction successfully preserves the original dependency assumption used in AR and NAR, retaining both generalization and performance. Experiments on 4 WMT benchmarks demonstrate that Diformer outperforms current united-modelling works with more than 1.5 BLEU points for both AR and NAR decoding, and is also competitive to the state-of-the-art independent AR and NAR models."
}

@inproceedings{wang-etal-2021-hi,
    abbr={HI-CMLM},
    selected={false},
    title = "{HI}-{CMLM}: Improve {CMLM} with Hybrid Decoder Input",
    author = "Wang, Minghan  and
      Jiaxin, Guo  and
      Wang, Yuxia  and
      Chen, Yimeng  and
      Chang, Su  and
      Wei, Daimeng  and
      Zhang, Min  and
      Tao, Shimin  and
      Yang, Hao",
    editor = "Belz, Anya  and
      Fan, Angela  and
      Reiter, Ehud  and
      Sripada, Yaji",
    booktitle = "Proceedings of the 14th International Conference on Natural Language Generation",
    month = aug,
    year = "2021",
    address = "Aberdeen, Scotland, UK",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.inlg-1.16/",
    doi = "10.18653/v1/2021.inlg-1.16",
    pages = "167--171",
    abstract = "Mask-predict CMLM (Ghazvininejad et al.,2019) has achieved stunning performance among non-autoregressive NMT models, but we find that the mechanism of predicting all of the target words only depending on the hidden state of [MASK] is not effective and efficient in initial iterations of refinement, resulting in ungrammatical repetitions and slow convergence. In this work, we mitigate this problem by combining copied source with embeddings of [MASK] in decoder. Notably. it{'}s not a straightforward copying that is shown to be useless, but a novel heuristic hybrid strategy {---} fence-mask. Experimental results show that it gains consistent boosts on both WMT14 En{\ensuremath{<}}-{\ensuremath{>}}De and WMT16 En{\ensuremath{<}}-{\ensuremath{>}}Ro corpus by 0.5 BLEU on average, and 1 BLEU for less-informative short sentences. This reveals that incorporating additional information by proper strategies is beneficial to improve CMLM, particularly translation quality of short texts and speeding up early-stage convergence."
}

@article{yu2021joint,
  abbr={MT},
  selected={false},
  title={Joint-training on Symbiosis Networks for Deep Nueral Machine Translation models},
  author={Yu, Zhengzhe and Guo, Jiaxin and Wang, Minghan and Wei, Daimeng and Shang, Hengchao and Li, Zongyao and Wu, Zhanglin and Wang, Yuxia and Chen, Yimeng and Su, Chang and others},
  journal={arXiv preprint arXiv:2112.11642},
  year={2021}
}

@inproceedings{guo-etal-2022-hw,
    abbr={MT},
    selected={false},
    title = "The {HW}-{TSC}{'}s Speech to Speech Translation System for {IWSLT} 2022 Evaluation",
    author = "Guo, Jiaxin  and
      Li, Yinglu  and
      Wang, Minghan  and
      Qiao, Xiaosong  and
      Wang, Yuxia  and
      Shang, Hengchao  and
      Su, Chang  and
      Chen, Yimeng  and
      Zhang, Min  and
      Tao, Shimin  and
      Yang, Hao  and
      Qin, Ying",
    editor = "Salesky, Elizabeth  and
      Federico, Marcello  and
      Costa-juss{\`a}, Marta",
    booktitle = "Proceedings of the 19th International Conference on Spoken Language Translation (IWSLT 2022)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland (in-person and online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.iwslt-1.26/",
    doi = "10.18653/v1/2022.iwslt-1.26",
    pages = "293--297",
    abstract = "The paper presents the HW-TSC{'}s pipeline and results of Offline Speech to Speech Translation for IWSLT 2022. We design a cascade system consisted of an ASR model, machine translation model and TTS model to convert the speech from one language into another language(en-de). For the ASR part, we find that better performance can be obtained by ensembling multiple heterogeneous ASR models and performing reranking on beam candidates. And we find that the combination of context-aware reranking strategy and MT model fine-tuned on the in-domain dataset is helpful to improve the performance. Because it can mitigate the problem that the inconsistency in transcripts caused by the lack of context. Finally, we use VITS model provided officially to reproduce audio files from the translation hypothesis."
}


@article{wang-etal-2022-uncertainty,
    abbr={Uncertainty},
    selected={false},
    title = "Uncertainty Estimation and Reduction of Pre-trained Models for Text Regression",
    author = "Wang, Yuxia  and
      Beck, Daniel  and
      Baldwin, Timothy  and
      Verspoor, Karin",
    editor = "Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "10",
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.39/",
    doi = "10.1162/tacl_a_00483",
    pages = "680--696",
    abstract = "State-of-the-art classification and regression models are often not well calibrated, and cannot reliably provide uncertainty estimates, limiting their utility in safety-critical applications such as clinical decision-making. While recent work has focused on calibration of classifiers, there is almost no work in NLP on calibration in a regression setting. In this paper, we quantify the calibration of pre- trained language models for text regression, both intrinsically and extrinsically. We further apply uncertainty estimates to augment training data in low-resource domains. Our experiments on three regression tasks in both self-training and active-learning settings show that uncertainty estimation can be used to increase overall performance and enhance model generalization."
}

@inproceedings{wang-etal-2020-learning,
    abbr={STS},
    selected={false},
    title = "Learning from Unlabelled Data for Clinical Semantic Textual Similarity",
    author = "Wang, Yuxia  and
      Verspoor, Karin  and
      Baldwin, Timothy",
    editor = "Rumshisky, Anna  and
      Roberts, Kirk  and
      Bethard, Steven  and
      Naumann, Tristan",
    booktitle = "Proceedings of the 3rd Clinical Natural Language Processing Workshop",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.clinicalnlp-1.25/",
    doi = "10.18653/v1/2020.clinicalnlp-1.25",
    pages = "227--233",
    abstract = "Domain pretraining followed by task fine-tuning has become the standard paradigm for NLP tasks, but requires in-domain labelled data for task fine-tuning. To overcome this, we propose to utilise domain unlabelled data by assigning pseudo labels from a general model. We evaluate the approach on two clinical STS datasets, and achieve r= 0.80 on N2C2-STS. Further investigation reveals that if the data distribution of unlabelled sentence pairs is closer to the test data, we can obtain better performance. By leveraging a large general-purpose STS dataset and small-scale in-domain training data, we obtain further improvements to r= 0.90, a new SOTA."
}

@inproceedings{wang-etal-2022-hw,
    abbr={Speech},
    selected={false},
    title = "The {HW}-{TSC}{'}s Offline Speech Translation System for {IWSLT} 2022 Evaluation",
    author = "Li, Yinglu  and
      Wang, Minghan  and
      Guo, Jiaxin  and
      Qiao, Xiaosong  and
      Wang, Yuxia  and
      Wei, Daimeng  and
      Su, Chang  and
      Chen, Yimeng  and
      Zhang, Min  and
      Tao, Shimin  and
      Yang, Hao  and
      Qin, Ying",
    editor = "Salesky, Elizabeth  and
      Federico, Marcello  and
      Costa-juss{\`a}, Marta",
    booktitle = "Proceedings of the 19th International Conference on Spoken Language Translation (IWSLT 2022)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland (in-person and online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.iwslt-1.20/",
    doi = "10.18653/v1/2022.iwslt-1.20",
    pages = "239--246",
    abstract = "This paper describes the HW-TSC{'}s designation of the Offline Speech Translation System submitted for IWSLT 2022 Evaluation. We explored both cascade and end-to-end system on three language tracks (en-de, en-zh and en-ja), and we chose the cascade one as our primary submission. For the automatic speech recognition (ASR) model of cascade system, there are three ASR models including Conformer, S2T-Transformer and U2 trained on the mixture of five datasets. During inference, transcripts are generated with the help of domain controlled generation strategy. Context-aware reranking and ensemble based anti-interference strategy are proposed to produce better ASR outputs. For machine translation part, we pretrained three translation models on WMT21 dataset and fine-tuned them on in-domain corpora. Our cascade system shows competitive performance than the known offline systems in the industry and academia."
}

@inproceedings{wang-etal-2021-length,
    abbr={MT},
    selected={false},
    title = "How Length Prediction Influence the Performance of Non-Autoregressive Translation?",
    author = "Wang, Minghan  and
      Jiaxin, Guo  and
      Wang, Yuxia  and
      Chen, Yimeng  and
      Chang, Su  and
      Shang, Hengchao  and
      Zhang, Min  and
      Tao, Shimin  and
      Yang, Hao",
    editor = "Bastings, Jasmijn  and
      Belinkov, Yonatan  and
      Dupoux, Emmanuel  and
      Giulianelli, Mario  and
      Hupkes, Dieuwke  and
      Pinter, Yuval  and
      Sajjad, Hassan",
    booktitle = "Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.blackboxnlp-1.14/",
    doi = "10.18653/v1/2021.blackboxnlp-1.14",
    pages = "205--213",
    abstract = "Length prediction is a special task in a series of NAT models where target length has to be determined before generation. However, the performance of length prediction and its influence on translation quality has seldom been discussed. In this paper, we present comprehensive analyses on length prediction task of NAT, aiming to find the factors that influence performance, as well as how it associates with translation quality. We mainly perform experiments based on Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), a representative NAT model, and evaluate it on two language pairs, En-De and En-Ro. We draw two conclusions: 1) The performance of length prediction is mainly influenced by properties of language pairs such as alignment pattern, word order or intrinsic length ratio, and is also affected by the usage of knowledge distilled data. 2) There is a positive correlation between the performance of the length prediction and the BLEU score."
}

@article{guo2021self,
  abbr={MT},
  selected={false},
  title={Self-distillation mixup training for non-autoregressive neural machine translation},
  author={Guo, Jiaxin and Wang, Minghan and Wei, Daimeng and Shang, Hengchao and Wang, Yuxia and Li, Zongyao and Yu, Zhengzhe and Wu, Zhanglin and Chen, Yimeng and Su, Chang and others},
  journal={arXiv preprint arXiv:2112.11640},
  year={2021}
}

@inproceedings{wang-etal-2022-hw-tscs,
    abbr={Speech},
    selected={false},
    title = "The {HW}-{TSC}{'}s Simultaneous Speech Translation System for {IWSLT} 2022 Evaluation",
    author = "Wang, Minghan  and
      Guo, Jiaxin  and
      Li, Yinglu  and
      Qiao, Xiaosong  and
      Wang, Yuxia  and
      Li, Zongyao  and
      Su, Chang  and
      Chen, Yimeng  and
      Zhang, Min  and
      Tao, Shimin  and
      Yang, Hao  and
      Qin, Ying",
    editor = "Salesky, Elizabeth  and
      Federico, Marcello  and
      Costa-juss{\`a}, Marta",
    booktitle = "Proceedings of the 19th International Conference on Spoken Language Translation (IWSLT 2022)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland (in-person and online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.iwslt-1.21/",
    doi = "10.18653/v1/2022.iwslt-1.21",
    pages = "247--254",
    abstract = "This paper presents our work in the participation of IWSLT 2022 simultaneous speech translation evaluation. For the track of text-to-text (T2T), we participate in three language pairs and build wait-k based simultaneous MT (SimulMT) model for the task. The model was pretrained on WMT21 news corpora, and was further improved with in-domain fine-tuning and self-training. For the speech-to-text (S2T) track, we designed both cascade and end-to-end form in three language pairs. The cascade system is composed of a chunking-based streaming ASR model and the SimulMT model used in the T2T track. The end-to-end system is a simultaneous speech translation (SimulST) model based on wait-k strategy, which is directly trained on a synthetic corpus produced by translating all texts of ASR corpora into specific target language with an offline MT model. It also contains a heuristic sentence breaking strategy, preventing it from finishing the translation before the the end of the speech. We evaluate our systems on the MUST-C tst-COMMON dataset and show that the end-to-end system is competitive to the cascade one. Meanwhile, we also demonstrate that the SimulMT model can be efficiently optimized by these approaches, resulting in the improvements of 1-2 BLEU points."
}

@inproceedings{wang-etal-2024-semeval-2024,
    abbr={SemEval2024MGT},
    selected={true},
    title = "{S}em{E}val-2024 Task 8: Multidomain, Multimodel and Multilingual Machine-Generated Text Detection",
    author = "Wang, Yuxia  and
      Mansurov, Jonibek  and
      Ivanov, Petar  and
      Su, Jinyan  and
      Shelmanov, Artem  and
      Tsvigun, Akim  and
      Mohammed Afzal, Osama  and
      Mahmoud, Tarek  and
      Puccetti, Giovanni  and
      Arnold, Thomas",
    editor = {Ojha, Atul Kr.  and
      Do{\u{g}}ru{\"o}z, A. Seza  and
      Tayyar Madabushi, Harish  and
      Da San Martino, Giovanni  and
      Rosenthal, Sara  and
      Ros{\'a}, Aiala},
    booktitle = "Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.semeval-1.279/",
    doi = "10.18653/v1/2024.semeval-1.279",
    pages = "2057--2079",
    abstract = "We present the results and the main findings of SemEval-2024 Task 8: Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection. The task featured three subtasks. Subtask A is a binary classification task determining whether a text is written by a human or generated by a machine. This subtask has two tracks: a monolingual track focused solely on English texts and a multilingual track. Subtask B is to detect the exact source of a text, discerning whether it is written by a human or generated by a specific LLM. Subtask C aims to identify the changing point within a text, at which the authorship transitions from human to machine. The task attracted a large number of participants: subtask A monolingual (126), subtask A multilingual (59), subtask B (70), and subtask C (30). In this paper, we present the task, analyze the results, and discuss the system submissions and the methods they used. For all subtasks, the best systems used LLMs."
}

@inproceedings{chen-etal-2021-hw,
    abbr={MT},
    selected={false},
    title = "{HW}-{TSC}{'}s Participation at {WMT} 2021 Quality Estimation Shared Task",
    author = "Chen, Yimeng  and
      Su, Chang  and
      Zhang, Yingtao  and
      Wang, Yuxia  and
      Geng, Xiang  and
      Yang, Hao  and
      Tao, Shimin  and
      Jiaxin, Guo  and
      Minghan, Wang  and
      Zhang, Min  and
      Liu, Yujia  and
      Huang, Shujian",
    editor = "Barrault, Loic  and
      Bojar, Ondrej  and
      Bougares, Fethi  and
      Chatterjee, Rajen  and
      Costa-jussa, Marta R.  and
      Federmann, Christian  and
      Fishel, Mark  and
      Fraser, Alexander  and
      Freitag, Markus  and
      Graham, Yvette  and
      Grundkiewicz, Roman  and
      Guzman, Paco  and
      Haddow, Barry  and
      Huck, Matthias  and
      Yepes, Antonio Jimeno  and
      Koehn, Philipp  and
      Kocmi, Tom  and
      Martins, Andre  and
      Morishita, Makoto  and
      Monz, Christof",
    booktitle = "Proceedings of the Sixth Conference on Machine Translation",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.wmt-1.92/",
    pages = "890--896",
    abstract = "This paper presents our work in WMT 2021 Quality Estimation (QE) Shared Task. We participated in all of the three sub-tasks, including Sentence-Level Direct Assessment (DA) task, Word and Sentence-Level Post-editing Effort task and Critical Error Detection task, in all language pairs. Our systems employ the framework of Predictor-Estimator, concretely with a pre-trained XLM-Roberta as Predictor and task-specific classifier or regressor as Estimator. For all tasks, we improve our systems by incorporating post-edit sentence or additional high-quality translation sentence in the way of multitask learning or encoding it with predictors directly. Moreover, in zero-shot setting, our data augmentation strategy based on Monte-Carlo Dropout brings up significant improvement on DA sub-task. Notably, our submissions achieve remarkable results over all tasks."
}

@article{wang2021hw,
  abbr={MT},
  selected={false},
  title={The HW-TSC's Offline Speech Translation Systems for IWSLT 2021 Evaluation},
  author={Wang, Minghan and Wang, Yuxia and Su, Chang and Guo, Jiaxin and Zhang, Yingtao and Liu, Yujia and Zhang, Min and Tao, Shimin and Zeng, Xingshan and Li, Liangyou and others},
  journal={arXiv preprint arXiv:2108.03845},
  year={2021}
}

@inproceedings{tao2021incorporating,
  abbr={MT},
  selected={false},
  title={Incorporating complete syntactical knowledge for spoken language understanding},
  author={Tao, Shimin and Qin, Ying and Chen, Yimeng and Du, Chunning and Sun, Haifeng and Meng, Weibin and Xiao, Yanghua and Guo, Jiaxin and Su, Chang and Wang, Minghan and others},
  booktitle={Knowledge Graph and Semantic Computing: Knowledge Graph Empowers New Infrastructure Construction: 6th China Conference, CCKS 2021, Guangzhou, China, November 4-7, 2021, Proceedings 6},
  pages={145--156},
  year={2021},
  organization={Springer}
}

@inproceedings{meng2021incorporating,
  abbr={MT},
  selected={false},
  title={Incorporating Complete Syntactical Knowledge for Spoken Language Understanding},
  author={Meng, Weibin and Xiao, Yanghua and Guo, Jiaxin and Su, Chang and Wang, Minghan and Zhang, Min and Wang, Yuxia and Yang, Hao},
  booktitle={Knowledge Graph and Semantic Computing: Knowledge Graph Empowers New Infrastructure Construction: 6th China Conference, CCKS 2021, Guangzhou, China, November 4-7, 2021, Proceedings},
  pages={145},
  year={2021},
  organization={Springer Nature}
}

@inproceedings{manzoor-etal-2024-machines,
    abbr={Empathy},
    selected={true},
    title = "Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of {LM}s",
    author = "Manzoor, Muhammad Arslan  and
      Wang, Yuxia  and
      Wang, Minghan  and
      Nakov, Preslav",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.861/",
    doi = "10.18653/v1/2024.findings-emnlp.861",
    pages = "14683--14701",
    abstract = "Empathy plays a pivotal role in fostering prosocial behavior, often triggered by the sharing of personal experiences through narratives. However, modeling empathy using NLP approaches remains challenging due to its deep interconnection with human interaction dynamics. Previous approaches, which involve fine-tuning language models (LMs) on human-annotated empathic datasets, have had limited success. In our pursuit of improving empathy understanding in LMs, we propose several strategies, including contrastive learning with masked LMs and supervised fine-tuning with large language models. While these methods show improvements over previous methods, the overall results remain unsatisfactory. To better understand this trend, we performed an analysis which reveals a low agreement among annotators. This lack of consensus hinders training and highlights the subjective nature of the task. We also explore the cultural impact on annotations. To study this, we meticulously collected story pairs in Urdu language and find that subjectivity in interpreting empathy among annotators appears to be independent of cultural background. Our systematic exploration of LMs' understanding of empathy reveals substantial opportunities for further investigation in both task formulation and modeling."
}

@phdthesis{wang2023towards,
  abbr={PhD Thesis},
  selected={false},
  title={Towards Accurate and Reliable Modelling for Semantic Textual Similarity},
  author={Wang, Yuxia},
  year={2023},
  school={The University of Melbourne},
  url={https://minerva-access.unimelb.edu.au/items/4e20a1c9-7e84-4cb9-a87e-a4153a90014c}
}


@inproceedings{wang-etal-2025-genai,
    abbr={GenAI-MGT},
    selected={false},
    title = "{G}en{AI} Content Detection Task 1: {E}nglish and Multilingual Machine-Generated Text Detection: {AI} vs. Human",
    author = "Wang, Yuxia  and
      Shelmanov, Artem  and
      Mansurov, Jonibek  and
      Tsvigun, Akim  and
      Mikhailov, Vladislav  and
      Xing, Rui  and
      Xie, Zhuohan  and
      Geng, Jiahui  and
      Puccetti, Giovanni  and
      Artemova, Ekaterina  and
      Su, Jinyan  and
      Ta, Minh Ngoc  and
      Abassy, Mervat  and
      Elozeiri, Kareem Ashraf  and
      El Etter, Saad El Dine Ahmed  and
      Goloburda, Maiya  and
      Mahmoud, Tarek  and
      Tomar, Raj Vardhan  and
      Laiyk, Nurkhan  and
      Mohammed Afzal, Osama  and
      Koike, Ryuto  and
      Kaneko, Masahiro  and
      Aji, Alham Fikri  and
      Habash, Nizar  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Alam, Firoj  and
      Nakov, Preslav  and
      Habash, Nizar  and
      Gurevych, Iryna  and
      Chowdhury, Shammur  and
      Shelmanov, Artem  and
      Wang, Yuxia  and
      Artemova, Ekaterina  and
      Kutlu, Mucahid  and
      Mikros, George",
    booktitle = "Proceedings of the 1stWorkshop on GenAI Content Detection (GenAIDetect)",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "International Conference on Computational Linguistics",
    url = "https://aclanthology.org/2025.genaidetect-1.27/",
    pages = "244--261",
    abstract = "We present the GenAI Content Detection Task 1 {--} a shared task on binary machine generated text detection, conducted as a part of the GenAI workshop at COLING 2025. The task consists of two subtasks: Monolingual (English) and Multilingual. The shared task attracted many participants: 36 teams made official submissions to the Monolingual subtask during the test phase and 27 teams {--} to the Multilingual. We provide a comprehensive overview of the data, a summary of the results {--} including system rankings and performance scores {--} detailed descriptions of the participating systems, and an in-depth analysis of submissions."
}


@article{wang2020multi,
  abbr={Medical},
  selected={false},
  title={A multi-pass sieve for clinical concept normalization},
  author={Wang, Yuxia and Hur, Brian and Verspoor, Karin and Baldwin, Timothy},
  journal={Traitement Automatique Des Langues},
  volume={61},
  number={2},
  pages={41--65},
  year={2020}
}

@inproceedings{wang-etal-2025-openfactcheck,
    abbr={OpenFactCheck},
    selected={true},
    title = "{O}pen{F}act{C}heck: Building, Benchmarking Customized Fact-Checking Systems and Evaluating the Factuality of Claims and {LLM}s",
    author = "Wang, Yuxia  and
      Wang, Minghan  and
      Iqbal, Hasan  and
      Georgiev, Georgi N.  and
      Geng, Jiahui  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.755/",
    pages = "11399--11421",
    abstract = "The increased use of large language models (LLMs) across a variety of real-world applications calls for mechanisms to verify the fac- tual accuracy of their outputs. Difficulties lie in assessing the factuality of free-form responses in open domains. Also, different pa- pers use disparate evaluation benchmarks and measurements, which renders them hard to compare and hampers future progress. To mitigate these issues, we propose OpenFactCheck, a unified framework for building customized automatic fact-checking systems, benchmarking their accuracy, evaluating factuality of LLMs, and verifying claims in a document. OpenFactCheck consists of three modules: (i) CUSTCHECKER allows users to easily customize an automatic fact-checker and verify the factual correctness of documents and claims, (ii) LLMEVAL, a unified evaluation framework assesses LLM{'}s factuality ability from various perspectives fairly, and (iii) CHECKEREVAL is an extensible solution for gauging the reliability of automatic fact-checkers' verification results using human-annotated datasets. Data and code are publicly available at https: //github.com/yuxiaw/openfactcheck."
}


@article{wang2025human,
  abbr={HumanEval MGT},
  selected={true},
  title={Is Human-Like Text Liked by Humans? Multilingual Human Detection and Preference Against AI},
  author={Wang, Yuxia and Xing, Rui and Mansurov, Jonibek and Puccetti, Giovanni and Xie, Zhuohan and Ta, Minh Ngoc and Geng, Jiahui and Su, Jinyan and Abassy, Mervat and Ahmed, Saad El Dine and others},
  journal={arXiv preprint arXiv:2502.11614},
  year={2025}
}

@article{goloburda2025qorgau,
  abbr={Kazakh Safety},
  selected={false},
  title={Qorgau: Evaluating LLM Safety in Kazakh-Russian Bilingual Contexts},
  author={Goloburda*, Maiya and Laiyk*, Nurkhan and Turmakhan*, Diana and Wang*, Yuxia and Togmanov, Mukhammed and Mansurov, Jonibek and Sametov, Askhat and Mukhituly, Nurdaulet and Wang, Minghan and Orel, Daniil and others},
  journal={ACL 2025 (Findings)},
  year={2025}
}

@article{laiyk2025instruction,
  abbr={Kazakh SFT},
  selected={false},
  title={Instruction Tuning on Public Government and Cultural Data for Low-Resource Language: a Case Study in Kazakh},
  author={Laiyk, Nurkhan and Orel, Daniil and Joshi, Rituraj and Goloburda, Maiya and Wang, Yuxia and Nakov, Preslav and Koto, Fajri},
  journal={ACL 2025},
  year={2025}
}

@article{togmanov2025kazmmlu,
  abbr={KazMMLU},
  selected={false},
  title={KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan},
  author={Togmanov, Mukhammed and Mukhituly, Nurdaulet and Turmakhan, Diana and Mansurov, Jonibek and Goloburda, Maiya and Sakip, Akhmed and Xie, Zhuohan and Wang, Yuxia and Syzdykov, Bekassyl and Laiyk, Nurkhan and others},
  journal={ACL 2025},
  year={2025}
}

@article{koto2025llama,
  abbr={KazLLM},
  selected={true},
  title={Llama-3.1-Sherkala-8B-Chat: An Open Large Language Model for Kazakh},
  author={Koto, Fajri and Joshi, Rituraj and Mukhituly, Nurdaulet and Wang, Yuxia and Xie, Zhuohan and Pal, Rahul and Orel, Daniil and Mullah, Parvez and Turmakhan, Diana and Goloburda, Maiya and others},
  journal={arXiv preprint arXiv:2503.01493},
  year={2025}
}

@article{geng2025comprehensive,
  abbr={Unlearning survey},
  selected={false},
  title={A comprehensive survey of machine unlearning techniques for large language models},
  author={Geng, Jiahui and Li, Qing and Woisetschlaeger, Herbert and Chen, Zongxiong and Cai, Fengyu and Wang, Yuxia and Nakov, Preslav and Jacobsen, Hans-Arno and Karray, Fakhri},
  journal={arXiv preprint arXiv:2503.01854},
  year={2025}
}

@article{wang2025speechdialoguefactory,
  abbr={SpeechDialogue},
  selected={true},
  title={SpeechDialogueFactory: Generating High-Quality Speech Dialogue Data to Accelerate Your Speech-LLM Development},
  author={Wang, Minghan and Bai, Ye and Wang, Yuxia and Vu, Thuy-Trang and Shareghi, Ehsan and Haffari, Gholamreza},
  journal={Interspeech 2025},
  year={2025}
}

@article{ta2025faid,
  abbr={FAID},
  selected={false},
  title={FAID: Fine-grained AI-generated Text Detection using Multi-task Auxiliary and Multi-level Contrastive Learning},
  author={Ta, Minh Ngoc and Van, Dong Cao and Hoang, Duc-Anh and Le-Anh, Minh and Nguyen, Truong and Nguyen, My Anh Tran and Wang, Yuxia and Nakov, Preslav and Dinh, Sang},
  journal={arXiv preprint arXiv:2505.14271},
  year={2025}
}

@article{ahmad2025urdufactcheck,
  abbr={UrduFactCheck},
  selected={false},
  title={UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence Boosting and Benchmarking},
  author={Ahmad, Sarfraz and Iqbal, Hasan and Ahsan, Momina and Naeem, Numaan and Khan, Muhammad Ahsan Riaz and Riaz, Arham and Manzoor, Muhammad Arslan and Wang, Yuxia and Nakov, Preslav},
  journal={arXiv preprint arXiv:2505.15063},
  year={2025}
}

@article{geng2025vscbench,
  abbr={VSCBench},
  selected={false},
  title={VSCBench: Bridging the Gap in Vision-Language Model Safety Calibration},
  author={Geng, Jiahui and Li, Qing and Chen, Zongxiong and Wang, Yuxia and Zhu, Derui and Xie, Zhuohan and Lyu, Chenyang and Chen, Xiuying and Nakov, Preslav and Karray, Fakhri},
  journal={ACL 2025 (Findings)},
  year={2025}
}


@inproceedings{abassy-etal-2024-llm,
    abbr={Llm-detectaive},
    selected={false},
    title = "{LLM}-{D}etect{AI}ve: a Tool for Fine-Grained Machine-Generated Text Detection",
    author = "Abassy, Mervat  and
      Elozeiri, Kareem  and
      Aziz, Alexander  and
      Ta, Minh Ngoc  and
      Tomar, Raj Vardhan  and
      Adhikari, Bimarsha  and
      Ahmed, Saad El Dine  and
      Wang, Yuxia  and
      Mohammed Afzal, Osama  and
      Xie, Zhuohan  and
      Mansurov, Jonibek  and
      Artemova, Ekaterina  and
      Mikhailov, Vladislav  and
      Xing, Rui  and
      Geng, Jiahui  and
      Iqbal, Hasan  and
      Mujahid, Zain Muhammad  and
      Mahmoud, Tarek  and
      Tsvigun, Akim  and
      Aji, Alham Fikri  and
      Shelmanov, Artem  and
      Habash, Nizar  and
      Gurevych, Iryna  and
      Nakov, Preslav",
    editor = "Hernandez Farias, Delia Irazu  and
      Hope, Tom  and
      Li, Manling",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-demo.35/",
    doi = "10.18653/v1/2024.emnlp-demo.35",
    pages = "336--343",
    abstract = "The ease of access to large language models (LLMs) has enabled a widespread of machine-generated texts, and now it is often hard to tell whether a piece of text was human-written or machine-generated. This raises concerns about potential misuse, particularly within educational and academic domains. Thus, it is important to develop practical systems that can automate the process. Here, we present one such system, LLM-DetectAIve, designed for fine-grained detection. Unlike most previous work on machine-generated text detection, which focused on binary classification, LLM-DetectAIve supports four categories: (i) human-written, (ii) machine-generated, (iii) machine-written, then machine-humanized, and (iv) human-written, then machine-polished. Category (iii) aims to detect attempts to obfuscate the fact that a text was machine-generated, while category (iv) looks for cases where the LLM was used to polish a human-written text, which is typically acceptable in academic writing, but not in education. Our experiments show that LLM-DetectAIve can effectively identify the above four categories, which makes it a potentially useful tool in education, academia, and other domains.LLM-DetectAIve is publicly accessible at https://github.com/mbzuai-nlp/LLM-DetectAIve. The video describing our system is available at https://youtu.be/E8eT{\_}bE7k8c."
}

@article{xie2025finchain,
    abbr={FinChain},
    selected={true},
    title={FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning}, 
    author={Zhuohan Xie and Dhruv Sahnan and Debopriyo Banerjee and Georgi Georgiev and Rushil Thareja and Hachem Madmoun and Jinyan Su and Aaryamonvikram Singh and Yuxia Wang and Rui Xing and Fajri Koto and Haonan Li and Ivan Koychev and Tanmoy Chakraborty and Salem Lahlou and Veselin Stoyanov and Preslav Nakov},
    year={2025},
    eprint={2506.02515},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2506.02515}, 
}

@article{li2025hd,
  abbr={HD-NDEs},
  selected={true},
  title={HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs},
  author={Li, Qing and Geng, Jiahui and Chen, Zongxiong and Zhu, Derui and Wang, Yuxia and Ma, Congbo and Lyu, Chenyang and Karray, Fakhri},
  journal={ACL 2025},
  year={2025}
}